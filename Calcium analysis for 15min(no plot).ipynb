{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4226adba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shuai'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d03af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python_temp\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Python_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd94043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks, peak_widths, savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fc951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_data(data, time_column, fluorescence_columns):\n",
    "    time = data[time_column] * (900 / data[time_column].max())\n",
    "    fluorescence_data = data[fluorescence_columns]\n",
    "    window_size = 120\n",
    "\n",
    "    # Rolling baseline correction\n",
    "    rolling_baseline_corrected = fluorescence_data.apply(\n",
    "        lambda x: (x - x.rolling(window=window_size, min_periods=1, center=True).median()) /\n",
    "                  x.rolling(window=window_size, min_periods=1, center=True).median(),\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    # Apply Savitzky-Golay filter for smoothing\n",
    "    smoothed_data = rolling_baseline_corrected.apply(\n",
    "        lambda x: savgol_filter(x, window_length=11, polyorder=3), axis=0\n",
    "    )\n",
    "\n",
    "    return time, smoothed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75663a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Peak Detection for Oscillation Analysis\n",
    "def enhanced_peak_detection(time, smoothed_data, prominence=0.05, height=0.05, distance=1, width_range=(1, 30)):\n",
    "    peak_details = []\n",
    "    for column in smoothed_data.columns:\n",
    "        # Find peaks with adjustable parameters\n",
    "        peaks, properties = find_peaks(\n",
    "            smoothed_data[column],\n",
    "            prominence=prominence,\n",
    "            height=height,\n",
    "            distance=distance\n",
    "        )\n",
    "        \n",
    "        # Calculate peak widths at half-prominence\n",
    "        widths, width_heights, left_ips, right_ips = peak_widths(smoothed_data[column], peaks, rel_height=0.5)\n",
    "        \n",
    "        valid_peaks = []\n",
    "        for i, peak_idx in enumerate(peaks):\n",
    "            width_seconds = widths[i] * (time.iloc[1] - time.iloc[0])\n",
    "            if width_range[0] <= width_seconds <= width_range[1]:\n",
    "                valid_peaks.append(i)\n",
    "\n",
    "        total_duration = time.iloc[-1] - time.iloc[0]\n",
    "        frequency = len(valid_peaks) / 900*1000\n",
    "\n",
    "        if len(valid_peaks) == 0:\n",
    "            # If no valid peaks are detected, fill with 0\n",
    "            peak_details.append({\n",
    "                \"Region\": column,\n",
    "                \"Time\": 0,\n",
    "                \"Amplitude\": 0,\n",
    "                \"Width\": 0,\n",
    "                \"Prominence\": 0,\n",
    "                \"Inter_Peak_Interval\": 0,\n",
    "                \"Rise_Time\": 0,\n",
    "                \"Decay_Time\": 0,\n",
    "                \"AUC\": 0,\n",
    "                \"Frequency\": frequency,\n",
    "                \"Peak_Number\": 0\n",
    "            })\n",
    "        else:\n",
    "            for i in valid_peaks:\n",
    "                peak_idx = peaks[i]\n",
    "                width_seconds = widths[i] * (time.iloc[1] - time.iloc[0])\n",
    "                inter_peak_interval = (time.iloc[peak_idx] - time.iloc[peaks[i-1]]) if i > 0 else 0\n",
    "\n",
    "                # Calculate Rise Time\n",
    "                left_base_idx = int(left_ips[i])\n",
    "                rise_time = time.iloc[peak_idx] - time.iloc[left_base_idx]\n",
    "\n",
    "                # Calculate Decay Time\n",
    "                right_base_idx = int(right_ips[i])\n",
    "                decay_time = time.iloc[right_base_idx] - time.iloc[peak_idx]\n",
    "\n",
    "                # Calculate AUC\n",
    "                auc = np.trapz(smoothed_data[column].iloc[left_base_idx:right_base_idx+1],\n",
    "                               time.iloc[left_base_idx:right_base_idx+1])\n",
    "\n",
    "                peak_details.append({\n",
    "                    \"Region\": column,\n",
    "                    \"Time\": time.iloc[peak_idx],\n",
    "                    \"Amplitude\": properties[\"peak_heights\"][i],\n",
    "                    \"Width\": width_seconds,\n",
    "                    \"Prominence\": properties[\"prominences\"][i],\n",
    "                    \"Inter_Peak_Interval\": inter_peak_interval,\n",
    "                    \"Rise_Time\": rise_time,\n",
    "                    \"Decay_Time\": decay_time,\n",
    "                    \"AUC\": auc,\n",
    "                    \"Frequency\": frequency,\n",
    "                    \"Peak_Number\": 1\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(peak_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696f6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_peak_data(\n",
    "    peak_df,\n",
    "    csv_filename,  # <-- required to prefix outputs\n",
    "    path='.',\n",
    "    aggregated_filename=None,\n",
    "    detailed_filename=None\n",
    "):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    peak_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Extract base name from input file (e.g., \"GBML198_raw.csv\" â†’ \"GBML198_raw\")\n",
    "    base = os.path.splitext(os.path.basename(csv_filename))[0]\n",
    "\n",
    "    # Generate default filenames with CSV prefix\n",
    "    if detailed_filename is None:\n",
    "        detailed_filename = f\"{base}_detailed_peak_data.csv\"\n",
    "    if aggregated_filename is None:\n",
    "        aggregated_filename = f\"{base}_aggregated_data.csv\"\n",
    "\n",
    "    # Full paths\n",
    "    detailed_path = os.path.join(path, detailed_filename)\n",
    "    aggregated_path = os.path.join(path, aggregated_filename)\n",
    "\n",
    "    # Export detailed data\n",
    "    peak_df.to_csv(detailed_path, index=False)\n",
    "\n",
    "    # Aggregate per Region\n",
    "    aggregated_df = peak_df.groupby('Region').agg({\n",
    "        'Amplitude': 'mean',\n",
    "        'Width': 'mean',\n",
    "        'Prominence': 'mean',\n",
    "        'Frequency': 'mean',\n",
    "        'AUC': 'mean',\n",
    "        'Inter_Peak_Interval': 'mean',\n",
    "        'Rise_Time': 'mean',\n",
    "        'Decay_Time': 'mean',\n",
    "        'Peak_Number': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Export aggregated\n",
    "    aggregated_df.to_csv(aggregated_path, index=False)\n",
    "\n",
    "    print(f\"Detailed peak data saved to: {detailed_path}\")\n",
    "    print(f\"Aggregated peak data saved to: {aggregated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3877ccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Mean1', 'Mean2', 'Mean3', 'Mean4', 'Mean5', 'Mean6', 'Mean7',\n",
      "       'Mean8', 'Mean9',\n",
      "       ...\n",
      "       'Mean144', 'Mean145', 'Mean146', 'Mean147', 'Mean148', 'Mean149',\n",
      "       'Mean150', 'Mean151', 'Mean152', 'Mean153'],\n",
      "      dtype='object', length=154)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"dmsoResults15min.csv\"\n",
    "data = pd.read_csv(csv_file)\n",
    "print(data.columns)\n",
    "fluorescence_columns = [col for col in data.columns if col != 'Time']\n",
    "time, smoothed_data = preprocess_data(data, 'Time', fluorescence_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fdd6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_df = enhanced_peak_detection(time, smoothed_data, prominence=0.05, height=0.05, distance=1, width_range=(1, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92c5ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region   Time  Amplitude      Width  Prominence  Inter_Peak_Interval  \\\n",
      "0  Mean1  864.0   0.664046  14.046477    0.725435                  0.0   \n",
      "1  Mean2  327.0   0.198667  12.012516    0.205264                  0.0   \n",
      "2  Mean3  279.0   0.317836   9.086748    0.326888                  0.0   \n",
      "3  Mean4    0.0   0.000000   0.000000    0.000000                  0.0   \n",
      "4  Mean5  864.0   0.083772  13.195030    0.084704                  0.0   \n",
      "\n",
      "   Rise_Time  Decay_Time       AUC  Frequency  Peak_Number  \n",
      "0        7.5         7.5  7.469615   1.111111            1  \n",
      "1        6.0         6.0  1.901648   1.111111            1  \n",
      "2        6.0         3.0  2.212049   1.111111            1  \n",
      "3        0.0         0.0  0.000000   0.000000            0  \n",
      "4        7.5         6.0  0.880020   1.111111            1  \n"
     ]
    }
   ],
   "source": [
    "print(peak_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2da15c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed peak data saved to: .\\dmsoResults15min_detailed_peak_data.csv\n",
      "Aggregated peak data saved to: .\\dmsoResults15min_aggregated_data.csv\n"
     ]
    }
   ],
   "source": [
    "export_peak_data(peak_df,csv_filename=csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea31cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
