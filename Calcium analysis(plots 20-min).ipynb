{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d03af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:\\Python_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd94043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks, peak_widths, savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_data(data, time_column, fluorescence_columns):\n",
    "    time = data[time_column] * (1200 / data[time_column].max())\n",
    "    fluorescence_data = data[fluorescence_columns]\n",
    "    window_size = 120\n",
    "\n",
    "    # Rolling baseline correction\n",
    "    rolling_baseline_corrected = fluorescence_data.apply(\n",
    "        lambda x: (x - x.rolling(window=window_size, min_periods=1, center=True).median()) /\n",
    "                  x.rolling(window=window_size, min_periods=1, center=True).median(),\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    # Apply Savitzky-Golay filter for smoothing\n",
    "    smoothed_data = rolling_baseline_corrected.apply(\n",
    "        lambda x: savgol_filter(x, window_length=11, polyorder=3), axis=0\n",
    "    )\n",
    "\n",
    "    return time, smoothed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75663a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Peak Detection for Oscillation Analysis\n",
    "def enhanced_peak_detection(time, smoothed_data, prominence=0.05, height=0.05, distance=1, width_range=(1, 30)):\n",
    "    peak_details = []\n",
    "    for column in smoothed_data.columns:\n",
    "        # Find peaks with adjustable parameters\n",
    "        peaks, properties = find_peaks(\n",
    "            smoothed_data[column],\n",
    "            prominence=prominence,\n",
    "            height=height,\n",
    "            distance=distance\n",
    "        )\n",
    "        \n",
    "        # Calculate peak widths at half-prominence\n",
    "        widths, width_heights, left_ips, right_ips = peak_widths(smoothed_data[column], peaks, rel_height=0.5)\n",
    "        \n",
    "        valid_peaks = []\n",
    "        for i, peak_idx in enumerate(peaks):\n",
    "            width_seconds = widths[i] * (time.iloc[1] - time.iloc[0])\n",
    "            if width_range[0] <= width_seconds <= width_range[1]:\n",
    "                valid_peaks.append(i)\n",
    "\n",
    "        total_duration = time.iloc[-1] - time.iloc[0]\n",
    "        frequency = len(valid_peaks) / 1200*1000\n",
    "\n",
    "        if len(valid_peaks) == 0:\n",
    "            # If no valid peaks are detected, fill with 0\n",
    "            peak_details.append({\n",
    "                \"Region\": column,\n",
    "                \"Time\": 0,\n",
    "                \"Amplitude\": 0,\n",
    "                \"Width\": 0,\n",
    "                \"Prominence\": 0,\n",
    "                \"Inter_Peak_Interval\": 0,\n",
    "                \"Rise_Time\": 0,\n",
    "                \"Decay_Time\": 0,\n",
    "                \"AUC\": 0,\n",
    "                \"Frequency\": frequency,\n",
    "                \"Peak_Number\": 0\n",
    "            })\n",
    "        else:\n",
    "            for i in valid_peaks:\n",
    "                peak_idx = peaks[i]\n",
    "                width_seconds = widths[i] * (time.iloc[1] - time.iloc[0])\n",
    "                inter_peak_interval = (time.iloc[peak_idx] - time.iloc[peaks[i-1]]) if i > 0 else 0\n",
    "\n",
    "                # Calculate Rise Time\n",
    "                left_base_idx = int(left_ips[i])\n",
    "                rise_time = time.iloc[peak_idx] - time.iloc[left_base_idx]\n",
    "\n",
    "                # Calculate Decay Time\n",
    "                right_base_idx = int(right_ips[i])\n",
    "                decay_time = time.iloc[right_base_idx] - time.iloc[peak_idx]\n",
    "\n",
    "                # Calculate AUC\n",
    "                auc = np.trapz(smoothed_data[column].iloc[left_base_idx:right_base_idx+1],\n",
    "                               time.iloc[left_base_idx:right_base_idx+1])\n",
    "\n",
    "                peak_details.append({\n",
    "                    \"Region\": column,\n",
    "                    \"Time\": time.iloc[peak_idx],\n",
    "                    \"Amplitude\": properties[\"peak_heights\"][i],\n",
    "                    \"Width\": width_seconds,\n",
    "                    \"Prominence\": properties[\"prominences\"][i],\n",
    "                    \"Inter_Peak_Interval\": inter_peak_interval,\n",
    "                    \"Rise_Time\": rise_time,\n",
    "                    \"Decay_Time\": decay_time,\n",
    "                    \"AUC\": auc,\n",
    "                    \"Frequency\": frequency,\n",
    "                    \"Peak_Number\": 1\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(peak_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peaks(time, smoothed_data, peak_df, csv_filename=None, save_path=None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for column in smoothed_data.columns:\n",
    "        plt.plot(time, smoothed_data[column], label=f'Region {column}')\n",
    "        region_peaks = peak_df[peak_df['Region'] == column]\n",
    "        plt.scatter(region_peaks['Time'], region_peaks['Amplitude'], marker='x')\n",
    "\n",
    "    plt.title('Calcium Trace with Detected Peaks')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('ΔF/F₀')\n",
    "\n",
    "    # If no save_path but a csv_filename is given, use it to generate filename\n",
    "    if save_path is None and csv_filename:\n",
    "        base_name = os.path.splitext(os.path.basename(csv_filename))[0]\n",
    "        save_path = f\"{base_name}_trace_peaks.pdf\"\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdcb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peaks_trace_matrix(time, smoothed_data, peak_df=None, n_cols=5, colormap='plasma', csv_filename=None, save_path=None):\n",
    "    num_rois = len(smoothed_data.columns)\n",
    "    n_rows = int(np.ceil(num_rois / n_cols))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5 * n_cols, 2 * n_rows), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    colors = plt.cm.get_cmap(colormap, num_rois)\n",
    "\n",
    "    for i, column in enumerate(smoothed_data.columns):\n",
    "        ax = axes[i]\n",
    "        color = colors(i)\n",
    "\n",
    "        ax.plot(time, smoothed_data[column], color=color, linewidth=1)\n",
    "\n",
    "        if peak_df is not None:\n",
    "            region_peaks = peak_df[peak_df['Region'] == column]\n",
    "            ax.scatter(region_peaks['Time'], region_peaks['Amplitude'], color='black', marker='x', s=10)\n",
    "\n",
    "        ax.set_title(column, fontsize=7)\n",
    "        ax.tick_params(labelsize=6)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(num_rois, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.suptitle('Calcium Traces with Detected Peaks (Matrix)', fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    # Auto-generate filename using CSV prefix if needed\n",
    "    if save_path is None and csv_filename:\n",
    "        base_name = os.path.splitext(os.path.basename(csv_filename))[0]\n",
    "        save_path = f\"{base_name}_trace_matrix.pdf\"\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traces_one_per_row(time, smoothed_data, csv_filename=None, save_path=None, colormap='jet'):\n",
    "    num_rois = len(smoothed_data.columns)\n",
    "    fig_width, fig_height = 12, 30  # A4 portrait\n",
    "\n",
    "    fig, axes = plt.subplots(num_rois, 1, figsize=(fig_width, fig_height), sharex=True)\n",
    "    if num_rois == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    colors = plt.cm.get_cmap(colormap, num_rois)\n",
    "\n",
    "    for i, (ax, column) in enumerate(zip(axes, smoothed_data.columns)):\n",
    "        color = colors(i)\n",
    "        trace = smoothed_data[column]\n",
    "\n",
    "        ax.plot(time, trace, color=color, linewidth=1)\n",
    "        ax.text(-0.02, 0.5, f'{i + 1}', transform=ax.transAxes,\n",
    "                va='center', ha='right', fontsize=7, color='black')\n",
    "\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        ax.tick_params(length=0)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "    # Time ticks only on bottom row\n",
    "    axes[-1].set_xticks(np.linspace(time.iloc[0], time.iloc[-1], 6))\n",
    "    axes[-1].tick_params(labelsize=8)\n",
    "    axes[-1].set_xlabel('Time (s)', fontsize=10)\n",
    "\n",
    "    fig.text(0.01, 0.5, 'ΔF/F₀', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "    plt.tight_layout(rect=[0.04, 0, 1, 0.97])\n",
    "\n",
    "    # Auto-generate save path if needed\n",
    "    if save_path is None and csv_filename:\n",
    "        base = os.path.splitext(os.path.basename(csv_filename))[0]\n",
    "        save_path = f\"{base}_traces_one_per_row.pdf\"\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of ΔF/F₀ Over Time\n",
    "def plot_dff_heatmap(time, smoothed_data, csv_filename=None, save_path=None):\n",
    "    num_rois = smoothed_data.shape[1]  # Number of ROI columns\n",
    "    \n",
    "    if save_path is None and csv_filename:\n",
    "        base_name = os.path.splitext(os.path.basename(csv_filename))[0]\n",
    "        save_path = f\"{base_name}_heatmap.pdf\"\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        smoothed_data.T,\n",
    "        cmap='jet',\n",
    "        xticklabels=100,\n",
    "        yticklabels=False,  # 🔁 Hide ROI names\n",
    "        cbar_kws={'label': 'ΔF/F₀'}#,\n",
    "        #vmin=-0.2,  # 🔒 fixed lower bound of color scale\n",
    "        #vmax=1.2    # 🔒 fixed upper bound of color scale\n",
    "    )\n",
    "    plt.title(f'Heatmap of ΔF/F₀ Over Time (Total ROIs: {num_rois})')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Region')\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_peak_data(\n",
    "    peak_df,\n",
    "    csv_filename,  # <-- required to prefix outputs\n",
    "    path='.',\n",
    "    aggregated_filename=None,\n",
    "    detailed_filename=None\n",
    "):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    peak_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Extract base name from input file (e.g., \"GBML198_raw.csv\" → \"GBML198_raw\")\n",
    "    base = os.path.splitext(os.path.basename(csv_filename))[0]\n",
    "\n",
    "    # Generate default filenames with CSV prefix\n",
    "    if detailed_filename is None:\n",
    "        detailed_filename = f\"{base}_detailed_peak_data.csv\"\n",
    "    if aggregated_filename is None:\n",
    "        aggregated_filename = f\"{base}_aggregated_data.csv\"\n",
    "\n",
    "    # Full paths\n",
    "    detailed_path = os.path.join(path, detailed_filename)\n",
    "    aggregated_path = os.path.join(path, aggregated_filename)\n",
    "\n",
    "    # Export detailed data\n",
    "    peak_df.to_csv(detailed_path, index=False)\n",
    "\n",
    "    # Aggregate per Region\n",
    "    aggregated_df = peak_df.groupby('Region').agg({\n",
    "        'Amplitude': 'mean',\n",
    "        'Width': 'mean',\n",
    "        'Prominence': 'mean',\n",
    "        'Frequency': 'mean',\n",
    "        'AUC': 'mean',\n",
    "        'Inter_Peak_Interval': 'mean',\n",
    "        'Rise_Time': 'mean',\n",
    "        'Decay_Time': 'mean',\n",
    "        'Peak_Number': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Export aggregated\n",
    "    aggregated_df.to_csv(aggregated_path, index=False)\n",
    "\n",
    "    print(f\"Detailed peak data saved to: {detailed_path}\")\n",
    "    print(f\"Aggregated peak data saved to: {aggregated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"50um2_APB.csv\"\n",
    "data = pd.read_csv(csv_file)\n",
    "print(data.columns)\n",
    "fluorescence_columns = [col for col in data.columns if col != 'Time']\n",
    "time, smoothed_data = preprocess_data(data, 'Time', fluorescence_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_df = enhanced_peak_detection(time, smoothed_data, prominence=0.05, height=0.05, distance=1, width_range=(1, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peaks(time, smoothed_data, peak_df, csv_filename=csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd250054",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peaks_trace_matrix(time, smoothed_data, peak_df, csv_filename=csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db62223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces_one_per_row(time, smoothed_data, csv_filename=csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae25e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dff_heatmap(time, smoothed_data, csv_filename=csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
